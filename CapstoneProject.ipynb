{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree 2020\n",
    "## Capstone Project\n",
    "Ashish kumar<br>February 18, 2020\n",
    "## Time Series Analysis of Air Quality Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Best Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set includes hourly air pollutants data from 12 nationally-controlled air-quality monitoring sites. So we can choose any of the given monitoring site dataset to work upon. <br><br> Instead of randomly picking any dataset, It is better to look for the null values. Lesser the null values, better will be the predictions.<br><br> Let us build Helper function for finding the best dataset with respect to null values. The idea is to compare the average of row-wise average null values of each multi-site data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRSA_Data_Aotizhongxin_20130301-20170228.csv\n",
      "PRSA_Data_Changping_20130301-20170228.csv\n",
      "PRSA_Data_Dingling_20130301-20170228.csv\n",
      "PRSA_Data_Dongsi_20130301-20170228.csv\n",
      "PRSA_Data_Guanyuan_20130301-20170228.csv\n",
      "PRSA_Data_Gucheng_20130301-20170228.csv\n",
      "PRSA_Data_Huairou_20130301-20170228.csv\n",
      "PRSA_Data_Nongzhanguan_20130301-20170228.csv\n",
      "PRSA_Data_Shunyi_20130301-20170228.csv\n",
      "PRSA_Data_Tiantan_20130301-20170228.csv\n",
      "PRSA_Data_Wanliu_20130301-20170228.csv\n",
      "PRSA_Data_Wanshouxigong_20130301-20170228.csv\n"
     ]
    }
   ],
   "source": [
    "data_path = 'beijing-multisite-airquality-data-set'\n",
    "# storing names of all datafiles\n",
    "file_names = [file_name[len(data_path)+1:] for file_name in glob.glob(data_path + '/*.csv')]\n",
    "for file_name in file_names: print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "def best_data_file(data_files, cache_file = ''):\n",
    "    \n",
    "    # create directory for storing the dataset\n",
    "    if not os.path.exists('dataset'):\n",
    "        os.mkdir('dataset')\n",
    "    \n",
    "    if os.listdir('dataset'):\n",
    "        # read from the cache file\n",
    "        cache_file = os.listdir('dataset')[0]\n",
    "        print('Reading from cache file: dataset/',cache_file, sep='')\n",
    "        return cache_file\n",
    "    \n",
    "    # Do the heavy lifting\n",
    "    best_file = ''\n",
    "    Min_average = math.inf \n",
    "    for file_name in data_files:\n",
    "        # Reading each datafile in dataframe\n",
    "        df = pd.read_csv(data_path+'/'+file_name)\n",
    "        \n",
    "        # overall average = average of (average of null value row-wise )\n",
    "        overall_average = df.isna().mean().mean()\n",
    "        if overall_average < Min_average:\n",
    "            Min_average = overall_average\n",
    "            best_file = file_name\n",
    "        # print(file_name)\n",
    "        # print(overall_average)\n",
    "        \n",
    "        # for visualizing row-wise percentages of null values\n",
    "        # print(df.isna().mean().round(4)*100)\n",
    "    \n",
    "    # copy the best file in the dataset folder\n",
    "    src = os.path.join(data_path,best_file)\n",
    "    dst = os.path.join('dataset',best_file)\n",
    "    copyfile(src,dst)\n",
    "    print('path created: '+dst)\n",
    "    return best_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from cache file: dataset/PRSA_Data_Nongzhanguan_20130301-20170228.csv\n"
     ]
    }
   ],
   "source": [
    "# test the function\n",
    "best_file = best_data_file(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>SO2</th>\n",
       "      <th>NO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>O3</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>RAIN</th>\n",
       "      <th>wd</th>\n",
       "      <th>WSPM</th>\n",
       "      <th>station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1024.5</td>\n",
       "      <td>-21.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Nongzhanguan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>1025.1</td>\n",
       "      <td>-22.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Nongzhanguan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>1025.3</td>\n",
       "      <td>-24.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>5.3</td>\n",
       "      <td>Nongzhanguan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>1026.2</td>\n",
       "      <td>-25.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Nongzhanguan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>1027.1</td>\n",
       "      <td>-24.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Nongzhanguan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year  month  day  hour  PM2.5  PM10  SO2   NO2     CO    O3  TEMP  \\\n",
       "0   1  2013      3    1     0    5.0  14.0  4.0  12.0  200.0  85.0  -0.5   \n",
       "1   2  2013      3    1     1    8.0  12.0  6.0  14.0  200.0  84.0  -0.7   \n",
       "2   3  2013      3    1     2    3.0   6.0  5.0  14.0  200.0  83.0  -1.2   \n",
       "3   4  2013      3    1     3    5.0   5.0  5.0  14.0  200.0  84.0  -1.4   \n",
       "4   5  2013      3    1     4    5.0   5.0  6.0  21.0  200.0  77.0  -1.9   \n",
       "\n",
       "     PRES  DEWP  RAIN   wd  WSPM       station  \n",
       "0  1024.5 -21.4   0.0  NNW   5.7  Nongzhanguan  \n",
       "1  1025.1 -22.1   0.0   NW   3.9  Nongzhanguan  \n",
       "2  1025.3 -24.6   0.0  NNW   5.3  Nongzhanguan  \n",
       "3  1026.2 -25.5   0.0    N   4.9  Nongzhanguan  \n",
       "4  1027.1 -24.5   0.0  NNW   3.2  Nongzhanguan  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(os.path.join(data_path,best_file))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
